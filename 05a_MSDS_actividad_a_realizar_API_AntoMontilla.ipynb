{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programación para *Data Science*\n",
    "\n",
    "\n",
    "Unidad 5: Adquisición de datos en Python - Ejercicios y preguntas\n",
    "------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios para practicar\n",
    "\n",
    "**Los siguientes 3 ejercicios** no puntuan para la actividad, pero os recomendamos que los intentéis resolver antes de pasar a los ejercicios sucesivos. También podéis encontrar las soluciones a estos ejercicios al final del Notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Implementad una función que retorne el primer precio del día de cambio de bitcoins (BTC) a dólares en Bitstamp. \n",
    "\n",
    "**Hint**: [Aquí](https://www.bitstamp.net/api/) encontraréis la documentación de la API de Bitstamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6945.7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "import requests\n",
    "import json\n",
    "def bit_usd():\n",
    "    response = requests.get('https://www.bitstamp.net/api/ticker/')\n",
    "    response.content\n",
    "    content_dict = json.loads(response.content)\n",
    "    content_dict\n",
    "    price = content_dict[\"open\"]\n",
    "    return price\n",
    "bit_usd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2\n",
    "-----------\n",
    "\n",
    "Modificad la función del ejercicio anterior para que devuelva el primer precio del día de cambio de bitcoins (BTC) a euros (EUR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6397.11'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "def bit_eur():\n",
    "    response = requests.get('https://www.bitstamp.net/api/v2/ticker/btceur') #modificar url por correspondiente a EUR\n",
    "    response.content\n",
    "    content_dict = json.loads(response.content)\n",
    "    content_dict\n",
    "    price = content_dict[\"open\"]\n",
    "    return price\n",
    "bit_eur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 3\n",
    "-----------\n",
    "\n",
    "Programad una función que devuelva la fecha y hora de los 15 próximos pases de la estación espacial internacional (ISS) sobre una localización concreta (especificada por su **longitud y latitud). La función debe devolver una lista de 15 elementos, cada uno de los cuales debe ser una cadena de caracteres con la fecha y la hora de los pases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios y preguntas teóricas para la PEC\n",
    "\n",
    "A continuación encontrareis **los ejercicios y preguntas teóricas** que debéis completar en esta PEC y que forman parte de la evaluación de esta unidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta 1\n",
    "----------\n",
    "\n",
    "Queremos saber los crímenes que se han producido en Reino Unido en una localización **(latitud, longitud)** y fecha concretas. Identificad qué métodos de la [API siguiente](https://data.police.uk/docs/) podemos utilizar para obtener la información y contestad a las siguientes preguntas. **(1 punto)**\n",
    "\n",
    "1. ¿A qué URL haremos la petición?\n",
    "2. ¿Qué tipo de petición HTTP (qué acción) deberemos realizar contra la API para obtener los datos deseados?\n",
    "3. ¿En qué formato obtendremos la respuesta de la API?\n",
    "4. ¿Qué parámetros deberemos proporcionar en la petición a la API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "1. La URL a realizar petición es \"https://data.police.uk/api/crimes-at-location?\", donde se le debe añadir los parámetros fecha \"date=2017-02\", latitud \"&lat=52.629729\" y longitud \"&lng=-1.131592\"\n",
    "2. Debemos realizar un request del tipo \"response = requests.get(URL)\", para luego cargar el contenido de la petición \"response.content\" y explorar los datos\n",
    "3. Json\n",
    "4. Fecha (2017-02), latitud (52.629729) y longitud (-1.13159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta 2 \n",
    "----------\n",
    "\n",
    "¿Qué es una API Key y para que se utiliza? ¿Por qué pensáis que algunos proveedores de datos y/o servicios requieren el acceso a sus APIs utilizando una API Key? **(1 punto)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Una API Key no es mas que una clave para poder concectarse con la aplicación respectiva y obtener la información deseada. Los proveedores de datos emplean este mecanismo para controlar (i.e. restringir) 'quien' y 'como' la información suministrada es utilizada y descargada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 1\n",
    "-----------\n",
    "\n",
    "Implementad una función que retorne el identificador de la primera transacción incluida en el último bloque minado en Bitcoin. Utilizad la [API de blockchain.com](https://www.blockchain.com/es/api/blockchain_api) **(2 puntos)**.\n",
    "\n",
    "**Hints**: \n",
    "\n",
    "- Empezad por identificar los métodos de la API, que parámetros necesitas para llamar a cada uno de ellos y que información devuelven.\n",
    "- Deberéis realizar más de una petición a la API para resolver el ejercicio.\n",
    "- Los identificadores (tanto de bloques como de transacciones) son también llamados “hash” (**block hash** o **tx hash**) y consisten en 64 caracteres hexadecimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-03 12:38:40 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): blockchain.info:443\n",
      "2020-01-03 12:38:40 [urllib3.connectionpool] DEBUG: https://blockchain.info:443 \"GET /latestblock HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00000000000000000001a54a19d2b6cc67615e04eed97fdb2f80f29cfdcafe92'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "def last_Bitblock():\n",
    "    response = requests.get('https://blockchain.info/latestblock') #URL que provee el latest block\n",
    "    content_dict = json.loads(response.content) #cargando contenido en json\n",
    "    identificador = content_dict[\"hash\"] #creando variable con identificador deseado\n",
    "    return identificador #retornando información\n",
    "\n",
    "last_Bitblock()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2\n",
    "-----------\n",
    "\n",
    "Crear una función que dado un identificador de transacción devuelva la suma de los valores **(value)** de las salidas de la transacción **(out)**. Ejecutad la función utilizando el identificador obtenido en el ejercicio anterior. **(1 punto)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "URL = 'https://blockchain.info/rawtx/$tx_hash'\n",
    "PARAMS = {\"prev_out\":{'hash': 'b6f6991d03df0e2e04dafffcd6bc418aac66049e2cd74b80f14ac86db1e3f0da'}}\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.90 Safari/537.36'}\n",
    "response = requests.get(url = URL, params = PARAMS, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: blockchain in /anaconda3/lib/python3.7/site-packages (1.4.4)\r\n",
      "Requirement already satisfied: enum-compat in /anaconda3/lib/python3.7/site-packages (from blockchain) (0.0.3)\r\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from blockchain) (0.17.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install blockchain\n",
    "from blockchain import blockexplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockchain.blockexplorer.Block at 0x1059db780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockexplorer.get_block('000000000000000016f9a2c3e0f4c1245ff24856a79c34806969f5084f410680')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 3\n",
    "-----------\n",
    "\n",
    "Programad una función que retorne el estado meteorológico actual en una cierta localización, definida por su código postal (**zip code**) y código de país (e.g: us, uk, es, fr, etc). La función debe devolver una lista de tuplas de dos elementos, correspondientes al resumen del estado actual del tiempo **(weather.main)** y a la descripción extendida **(weather.description)**. Utilizad la API de [openweathermap](https://openweathermap.org/api) para obtener las predicciones **(1 punto)**\n",
    "\n",
    "Para utilizar la API necesitareis registraros y obtener una API key. Podéis registraros [aquí](https://home.openweathermap.org/users/sign_up) y obtener vuestra API key [aquí](https://home.openweathermap.org/api_keys) una vez registrados. Tened en cuenta que la API key puede tardar un rato en funcionar después de registraros, y la API os devolverá un error 401 conforme la clave no es valida:\n",
    "\n",
    "`{\"cod\":401, \"message\": \"Invalid API key. Please see http://openweathermap.org/faq#error401 for more info.\"}`\n",
    "\n",
    "Simplemente esperad un rato antes de utilizar la clave.\n",
    "\n",
    "**Hints**: \n",
    "\n",
    "Veréis que en general la API esta documentada sin incluir la API key, aun que esta es necesaria. Deberéis incluir la API key en la llamada como uno de los parámetros de la URL (&appid=your_api_key):\n",
    "\n",
    "    http://example_url.com?param1=value1&param2=value2&appid=your_api_key\n",
    "\n",
    "Os animamos a que paséis por el proceso de registro para que veáis de que trata y cómo se generan las API keys. Aún así, os proporcionamos una API key en caso de que tengáis problemas con el proceso.\n",
    "\n",
    "    owm_api_key = 'd54f26dbcf6d4136bc0ef8ba5f07825b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-03 12:18:00 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): api.openweathermap.org:443\n",
      "2020-01-03 12:18:01 [urllib3.connectionpool] DEBUG: https://api.openweathermap.org:443 \"GET /data/2.5/weather?zip=28014,es&appid=1a35856eceb78a55bcaa193fd3f242a0 HTTP/1.1\" 200 435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fog', 'fog']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "def tiempo_now(zip_co, countr):\n",
    "    #definiendo parametros para petición\n",
    "    api_key = '&appid=1a35856eceb78a55bcaa193fd3f242a0'\n",
    "    URL = 'https://api.openweathermap.org/data/2.5/weather?'\n",
    "    params = 'zip=%s,%s&appid=1a35856eceb78a55bcaa193fd3f242a0' % (zip_co, countr)\n",
    "    #ejecutando petición\n",
    "    response = requests.get(URL+params)\n",
    "    #cargando petición en diccionario para luego guardar información deseada\n",
    "    content_dict = json.loads(response.content)\n",
    "    out1 = content_dict[\"weather\"][0]['main']\n",
    "    out2 = content_dict[\"weather\"][0]['description']\n",
    "    out = [out1, out2]\n",
    "    return out\n",
    "\n",
    "tiempo_now(28014, 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 4\n",
    "-----------\n",
    "\n",
    "Modificad la función anterior para que reciba como input una **dirección** en concreto y devuelva la misma información (utilizando la misma API). **(1.5 puntos)**\n",
    "\n",
    "**Hints**: \n",
    "- Openweathermap no funciona directamente con direcciones, por lo que deberéis utilizar otra API ([googlemaps](https://developers.google.com/maps/documentation/) o [openstreetmaps](https://wiki.openstreetmap.org/wiki/Nominatim)) para convertir las direcciones a localizaciones (**lat, lng**).\n",
    "\n",
    "- openstreetmap no requiere API key, pero googlemaps sí. De nuevo, os animemos a que os registréis en la API de Google Maps* para conocer el proceso (si es que utilizáis este método). Aun así, de nuevo, os proporcionamos una clave por si acaso:\n",
    "\n",
    "    gm_api_key = 'AIzaSyA8MWitYiTSo9jBLrqp3c4lwHiilXxDYDo'\n",
    "\n",
    "    \\* És muy probable que la API de Google Maps os pida datos bancarios en el proceso de registro, aún que no os realizara ningún cargo en los primeros 12 meses y podréis cancelar la subscripción en cualquier momento. En cualquier caso, si sois reticentes, utilizad la clave proporcionada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlemaps in /anaconda3/lib/python3.7/site-packages (4.0.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in /anaconda3/lib/python3.7/site-packages (from googlemaps) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.8)\n"
     ]
    }
   ],
   "source": [
    "# Respuesta\n",
    "#importando libreria de googlemaps\n",
    "!pip install googlemaps\n",
    "import googlemaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-03 12:29:16 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): maps.googleapis.com:443\n",
      "2020-01-03 12:29:17 [urllib3.connectionpool] DEBUG: https://maps.googleapis.com:443 \"GET /maps/api/geocode/json?address=Calle+del+Gobernador%2C+31%2C+Madrid&key=AIzaSyCW4CSXsin5a6OJNzLL3e_BHUzAKBsOOgA HTTP/1.1\" 200 None\n",
      "2020-01-03 12:29:17 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): api.openweathermap.org:443\n",
      "2020-01-03 12:29:17 [urllib3.connectionpool] DEBUG: https://api.openweathermap.org:443 \"GET /data/2.5/weather?zip=28014,es&appid=1a35856eceb78a55bcaa193fd3f242a0 HTTP/1.1\" 200 437\n",
      "2020-01-03 12:29:17 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): api.openweathermap.org:443\n",
      "2020-01-03 12:29:17 [urllib3.connectionpool] DEBUG: https://api.openweathermap.org:443 \"GET /data/2.5/weather?zip=28014,es&appid=1a35856eceb78a55bcaa193fd3f242a0 HTTP/1.1\" 200 437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Mist', 'mist']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tiempo_dir(address):\n",
    "    api_key = 'AIzaSyCW4CSXsin5a6OJNzLL3e_BHUzAKBsOOgA' #creada con cuenta personal\n",
    "    #api_key esta restringida (need to change here https://console.cloud.google.com/google/maps-apis/overview?project=neoland-project&folder=&organizationId=)\n",
    "    #signing up\n",
    "    gmaps = googlemaps.Client(key=api_key)\n",
    "    #probando indicaciones de mi dirección en Madrid\n",
    "    geocode_result = gmaps.geocode(address)\n",
    "    zip_co = geocode_result[0]['address_components'][6]['long_name']\n",
    "    countr = str(geocode_result[0]['address_components'][5]['short_name'])\n",
    "    countr = countr.lower()\n",
    "    tiempo_now(zip_co, countr)\n",
    "    #Ahora usando los inputs _zip_code y _countr_ para obtener condiciones del tiempo\n",
    "    URL = 'https://api.openweathermap.org/data/2.5/weather?'\n",
    "    params = 'zip=%s,%s&appid=1a35856eceb78a55bcaa193fd3f242a0' % (zip_co, countr)\n",
    "    #ejecutando petición\n",
    "    response = requests.get(URL+params)\n",
    "    #cargando petición en diccionario para luego guardar información deseada\n",
    "    content_dict = json.loads(response.content)\n",
    "    out1 = content_dict[\"weather\"][0]['main']\n",
    "    out2 = content_dict[\"weather\"][0]['description']\n",
    "    out = [out1, out2]\n",
    "    return out\n",
    "\n",
    "\n",
    "tiempo_dir('Calle del Gobernador, 31, Madrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 5\n",
    "-----------\n",
    "\n",
    "[CoinMarketCap](https://coinmarketcap.com/) es una web con contenido acerca de\n",
    "las 100 criptomonedas con más capitalización de mercado.\n",
    "\n",
    "Programad un _crawler_ que extraiga los nombres y la capitalización de todas les monedas que se muestran en CoinMarketCap. **(2.5 puntos)**\n",
    "\n",
    "Para hacerlo, utilizad la estructura de _crawler_ que hemos visto en el Notebook de esta unidad **modificando únicamente dos lineas de código**:\n",
    "- L'URL de inicio.\n",
    "- La expresión XPath que selecciona el contenido a capturar.\n",
    "\n",
    "**Pista**: tal vez os puede ser de utilidad investigar sobre la scrapy shell y utilizarla para encontrar la expresión XPath que necesitas para resolver el ejercicio.\n",
    "\n",
    "**Nota**: si la ejecución del _crawler_ os retorna un error `ReactorNotRestartable`, reiniciad el núcleo del Notebook (en el meú: `Kernel` - `Restart`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in /anaconda3/lib/python3.7/site-packages (1.8.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /anaconda3/lib/python3.7/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (19.0.0)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in /anaconda3/lib/python3.7/site-packages (from scrapy) (4.7.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /anaconda3/lib/python3.7/site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: protego>=0.1.15 in /anaconda3/lib/python3.7/site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (1.5.2)\n",
      "Requirement already satisfied: Twisted>=17.9.0; python_version >= \"3.5\" in /anaconda3/lib/python3.7/site-packages (from scrapy) (19.10.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (2.7)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /anaconda3/lib/python3.7/site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (4.3.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from scrapy) (1.12.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in /anaconda3/lib/python3.7/site-packages (from service-identity>=16.0.0->scrapy) (19.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in /anaconda3/lib/python3.7/site-packages (from service-identity>=16.0.0->scrapy) (0.2.7)\n",
      "Requirement already satisfied: pyasn1 in /anaconda3/lib/python3.7/site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from zope.interface>=4.1.3->scrapy) (41.0.1)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /anaconda3/lib/python3.7/site-packages (from Twisted>=17.9.0; python_version >= \"3.5\"->scrapy) (19.0.0)\n",
      "Requirement already satisfied: Automat>=0.3.0 in /anaconda3/lib/python3.7/site-packages (from Twisted>=17.9.0; python_version >= \"3.5\"->scrapy) (0.8.0)\n",
      "Requirement already satisfied: incremental>=16.10.1 in /anaconda3/lib/python3.7/site-packages (from Twisted>=17.9.0; python_version >= \"3.5\"->scrapy) (17.5.0)\n",
      "Requirement already satisfied: PyHamcrest>=1.9.0 in /anaconda3/lib/python3.7/site-packages (from Twisted>=17.9.0; python_version >= \"3.5\"->scrapy) (1.9.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /anaconda3/lib/python3.7/site-packages (from Twisted>=17.9.0; python_version >= \"3.5\"->scrapy) (15.1.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /anaconda3/lib/python3.7/site-packages (from cryptography>=2.0->scrapy) (1.12.3)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /anaconda3/lib/python3.7/site-packages (from cryptography>=2.0->scrapy) (0.24.0)\n",
      "Requirement already satisfied: idna>=2.5 in /anaconda3/lib/python3.7/site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0; python_version >= \"3.5\"->scrapy) (2.8)\n",
      "Requirement already satisfied: pycparser in /anaconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos Scrapy.\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Creamos la araña.\n",
    "class neoland_spider(scrapy.Spider):\n",
    "    \n",
    "    # Asignamos un nombre a la araña.\n",
    "    name = \"neoland_spider\"\n",
    "    \n",
    "    # Indicamos la URL que queremos analizar.\n",
    "    # Incluid aquí la URL de inicio:\n",
    "    ################################################\n",
    "    start_urls = [\n",
    "        \"https://coinmarketcap.com/all/views/all/\"\n",
    "    ]\n",
    "    ################################################\n",
    "    \n",
    "    # Definimos el analizador.\n",
    "    def parse(self, response):\n",
    "        # Extraemos el nombre de la moneda.\n",
    "        # Incluid aquí la expresión 'xpath' que nos retorna los nombres de las monedas.\n",
    "        ################################################\n",
    "        for currency in response.xpath('//a[@class=\"cmc-link\"]/@title'):\n",
    "        ################################################\n",
    "            yield {\n",
    "                'currency': currency.extract()\n",
    "            }\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-02 20:22:24 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: scrapybot)\n",
      "2020-01-02 20:22:24 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 16:54:48) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Darwin-15.6.0-x86_64-i386-64bit\n",
      "2020-01-02 20:22:24 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
      "2020-01-02 20:22:24 [scrapy.extensions.telnet] INFO: Telnet Password: 2a79eda9fdf95778\n",
      "2020-01-02 20:22:24 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-01-02 20:22:24 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-01-02 20:22:24 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-01-02 20:22:24 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-01-02 20:22:24 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-01-02 20:22:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-01-02 20:22:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-01-02 20:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://coinmarketcap.com/all/views/all/> (referer: None)\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Go to homepage'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bitcoin'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ethereum'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'XRP'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Tether'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bitcoin Cash'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Litecoin'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'EOS'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Binance Coin'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bitcoin SV'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Stellar'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Tezos'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'TRON'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Cardano'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'UNUS SED LEO'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Cosmos'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Monero'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Huobi Token'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Chainlink'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Neo'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'USD Coin'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ethereum Classic'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'HedgeTrade'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'IOTA'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Maker'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Crypto.com Coin'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Dash'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ontology'}\n",
      "2020-01-02 20:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'VeChain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'NEM'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Basic Attention Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Dogecoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Zcash'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Paxos Standard'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'FTX Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Synthetix Network Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Decred'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'TrueUSD'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Qtum'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ravencoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Algorand'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': '0x'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Seele'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'OKB'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Waves'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Holo'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Augur'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Centrality'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bitcoin Gold'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'ZB Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Nano'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'OmiseGO'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Swipe'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'ABBC Coin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Molecular Future'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'THETA'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'KuCoin Shares'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'DigiByte'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Horizen'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Lisk'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'LUNA'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bytom'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'MCO'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Nexo'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Enjin Coin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bitcoin Diamond'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'BitTorrent'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Komodo'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'ICON'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'IOST'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Verge'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Siacoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'V Systems'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'MonaCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'HyperCash'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Energi'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'DxChain Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bytecoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Quant'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Steem'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Zilliqa'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'BlockStamp'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'BitShares'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Single Collateral DAI '}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'EDUCare'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Matic Network'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Aeternity'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ardor'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Silverway'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'STASIS EURO'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'DigixDAO'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'MaidSafeCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Decentraland'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Electroneum'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Aidos Kuneen'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Crypterium'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Nash Exchange'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'SOLVE'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Status'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Kyber Network'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'iExec RLC'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'RIF Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Stratis'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'TomoChain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Digitex Futures'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Pundi X'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ren'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Grin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Metaverse ETP'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Golem'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'aelf'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Enigma'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Beam'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Zcoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Chiliz'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Fetch.ai'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Elastos'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'GXChain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Huobi Pool Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Thunder Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Aave'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ripio Credit Network'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Hyperion'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'FunFair'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bread'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Loopring'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Hedera Hashgraph'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Newton'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'WaykiChain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Tierion'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Revain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Populous'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Aion'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Factom'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Fantom'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'ReddCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Wanchain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Nebulas'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Lambda'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Diamond Platform Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'IoTeX'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'WINk'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Divi'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'MX Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Binance USD'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'XMax'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Loki'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'TrueChain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'YOU COIN'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'NULS'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'EDC Blockchain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'WAX'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ark'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'ILCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Harmony'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'KickToken'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Gatechain Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ignis'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'BHPCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Bancor'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'QASH'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Dragon Coins'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Power Ledger'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Loom Network'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Waltonchain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Telcoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Numeraire'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'NPCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Wirex Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Robotina'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Storj'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'PIVX'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Dent'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Metal'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Cred'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Celer Network'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Ocean Protocol'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Groestlcoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Civic'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Credits'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Aragon'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Gnosis'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Syscoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Santiment Network Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Dentacoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'GoChain'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'BHEX Token'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Cindicator'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Project Pai'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'BitKan'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Nexus'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'MediBloc [ERC20]'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Aurora'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'ZTCoin'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Elrond'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'sUSD'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Arcblock'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Orbs'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'B2BX'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'CryptoFranc'}\n",
      "2020-01-02 20:22:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://coinmarketcap.com/all/views/all/>\n",
      "{'currency': 'Moeda Loyalty Points'}\n",
      "2020-01-02 20:22:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-01-02 20:22:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 300,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 132391,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.397926,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 1, 2, 19, 22, 26, 335500),\n",
      " 'item_scraped_count': 201,\n",
      " 'log_count/DEBUG': 202,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 67260416,\n",
      " 'memusage/startup': 67260416,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2020, 1, 2, 19, 22, 24, 937574)}\n",
      "2020-01-02 20:22:26 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Creamos un crawler.\n",
    "    process = CrawlerProcess({\n",
    "        'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36',\n",
    "        'DOWNLOAD_HANDLERS': {'s3': None},\n",
    "        'LOG_ENABLED': True\n",
    "    })\n",
    "\n",
    "    # Inicializamos el crawler con nuestra araña.\n",
    "    process.crawl(neoland_spider)\n",
    "    \n",
    "    # Lanzamos la araña.\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio opcional\n",
    "\n",
    "Modificar la función anterior para que en vez de retornar únicamente el nombre de la moneda retorne una tupla con el nombre y la capitalización de mercado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucions als exercicis per a practicar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Implementad una función que retorne el primer precio del día de cambio de bitcoins (BTC) a dólares en Bitstamp. \n",
    "\n",
    "**Hint**: [Aquí](https://www.bitstamp.net/api/) encontraréis la documentación de la API de Bitstamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5440.95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos la librería requests\n",
    "import requests\n",
    "# Importamos la librería json\n",
    "import json\n",
    "\n",
    "# Definimos la función\n",
    "def first_btc_price_usd():\n",
    "    \"\"\"\n",
    "    Retorna un float con el primer precio del día de cambio de bitcoins\n",
    "    (BTC) a dólares (USD) en Bitstamp.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get('https://www.bitstamp.net/api/ticker/')\n",
    "    content_dict = json.loads(response.content)\n",
    "    price = content_dict[\"open\"]\n",
    "   \n",
    "    return price\n",
    "\n",
    "first_btc_price_usd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2\n",
    "-----------\n",
    "\n",
    "Modificad la función del ejercicio anterior para que devuelva el primer precio del día de cambio de bitcoins (BTC) a euros (EUR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4887.99"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos la librería requests\n",
    "import requests\n",
    "# Importamos la librería json\n",
    "import json\n",
    "\n",
    "# Definim la funció\n",
    "def first_btc_price_eur():\n",
    "    \"\"\"\n",
    "    Retorna un float con el primer precio del día de cambio de bitcoins\n",
    "    (BTC) a euros (EUR) en Bitstamp.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get('https://www.bitstamp.net/api/v2/ticker/btceur')\n",
    "    content_dict = json.loads(response.content)\n",
    "    price = content_dict[\"open\"]\n",
    "   \n",
    "    return float(price)\n",
    "\n",
    "first_btc_price_eur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 3\n",
    "-----------\n",
    "\n",
    "Programad una función que devuelva la fecha y hora de los 15 próximos pases de la estación espacial internacional (ISS) sobre una localización concreta (especificada por su **longitud y latitud). La función debe devolver una lista de 15 elementos, cada uno de los cuales debe ser una cadena de caracteres con la fecha y la hora de los pases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-04-26 03:29:42',\n",
       " '2019-04-26 05:02:22',\n",
       " '2019-04-26 06:38:55',\n",
       " '2019-04-26 08:16:45',\n",
       " '2019-04-26 09:54:08',\n",
       " '2019-04-26 11:30:43',\n",
       " '2019-04-26 13:07:42',\n",
       " '2019-04-27 04:12:03',\n",
       " '2019-04-27 05:47:55',\n",
       " '2019-04-27 07:25:35',\n",
       " '2019-04-27 09:03:12',\n",
       " '2019-04-27 10:39:57',\n",
       " '2019-04-27 12:16:38',\n",
       " '2019-04-28 03:22:05',\n",
       " '2019-04-28 04:57:03']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos la librerías necesarias\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_iss_overhead(lo, lat):\n",
    "    \"\"\"\n",
    "    Muestra la fecha y la hora de los 15 próximos pases de la ISS\n",
    "    sobre las coordenadas especificadas por parámetro.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Realizamos la petición GET con los parámetros recibidos\n",
    "    url = 'http://api.open-notify.org/iss-pass.json'\n",
    "    params = '?lat=%s&lon=%s&n=15' % (lo, lat)\n",
    "    response = requests.get(url+params)\n",
    "    content_dict = json.loads(response.content)\n",
    "    \n",
    "    # Se obtienen las fechas de la respuesta de la API en formato unixtime\n",
    "    # y se devuelven en formato Y-m-d H:M:S\n",
    "    r = []\n",
    "    for result in content_dict[\"response\"]:\n",
    "        r.append(datetime.utcfromtimestamp(result[\"risetime\"]).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "get_iss_overhead(41.406498,2.1923545)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
